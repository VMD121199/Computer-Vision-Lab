{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import (\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Lambda,\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.applications.mobilenet_v2 import (\n",
    "    MobileNetV2,\n",
    "    preprocess_input as mbv2_preprocess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/train/\"\n",
    "labels_path = \"./data/labels.csv\"\n",
    "img_size = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(labels_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image_path\"] = data_dir + df[\"id\"] + \".jpg\"\n",
    "df = df.drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breeds = sorted(df[\"breed\"].unique().tolist())\n",
    "len(breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num = dict(zip(breeds, range(len(breeds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all images into 1 array n value [n, x1, x2, x3]: <br>\n",
    "n: number of images<br>\n",
    "x1: height of image<br>\n",
    "x2: width of image<br>\n",
    "x3: depth of image(1 for grayscale image, 3 for color image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(data: pd.DataFrame, image_size: tuple):\n",
    "    X = np.zeros(\n",
    "        [len(data), image_size[0], image_size[1], image_size[2]],\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "    y = np.zeros([len(data), 1], dtype=np.uint8)\n",
    "    for idx, row in tqdm(data.iterrows()):\n",
    "        img_pixels = load_img(row[\"image_path\"], target_size=image_size)\n",
    "        X[idx] = img_pixels\n",
    "        y[idx] = class_to_num[row[\"breed\"]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [00:38, 266.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = image_processing(df, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract feature using MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, model_preprocess, image_size: tuple, data):\n",
    "    input_layer = Input(image_size)\n",
    "    processor = Lambda(model_preprocess)(input_layer)\n",
    "    base_model = model(\n",
    "        weights=\"imagenet\", include_top=False, input_shape=image_size\n",
    "    )(processor)\n",
    "    maxPool = MaxPooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs=input_layer, outputs=maxPool)\n",
    "    feature_maps = feature_extractor.predict(data, batch_size=64, verbose=1)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 84s 520ms/step\n"
     ]
    }
   ],
   "source": [
    "features = extract_feature(MobileNetV2, mbv2_preprocess, img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, y, test_size=0.2, random_state=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1280)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1474688   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 120)               15480     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,490,168\n",
      "Trainable params: 1,490,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(X_train.shape[1:]))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(len(breeds), activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "128/128 [==============================] - 2s 10ms/step - loss: 4.1912 - accuracy: 0.2284 - val_loss: 3.1802 - val_accuracy: 0.4572\n",
      "Epoch 2/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 2.2540 - accuracy: 0.5931 - val_loss: 1.6546 - val_accuracy: 0.6572\n",
      "Epoch 3/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.3066 - accuracy: 0.7174 - val_loss: 1.2103 - val_accuracy: 0.6890\n",
      "Epoch 4/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.9763 - accuracy: 0.7661 - val_loss: 1.0188 - val_accuracy: 0.7198\n",
      "Epoch 5/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.7980 - accuracy: 0.8010 - val_loss: 0.9323 - val_accuracy: 0.7379\n",
      "Epoch 6/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.6896 - accuracy: 0.8272 - val_loss: 0.8722 - val_accuracy: 0.7501\n",
      "Epoch 7/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.6048 - accuracy: 0.8438 - val_loss: 0.8446 - val_accuracy: 0.7565\n",
      "Epoch 8/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.5373 - accuracy: 0.8646 - val_loss: 0.8189 - val_accuracy: 0.7535\n",
      "Epoch 9/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.4791 - accuracy: 0.8789 - val_loss: 0.7806 - val_accuracy: 0.7687\n",
      "Epoch 10/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.4301 - accuracy: 0.8951 - val_loss: 0.7770 - val_accuracy: 0.7653\n",
      "Epoch 11/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3811 - accuracy: 0.9108 - val_loss: 0.7649 - val_accuracy: 0.7638\n",
      "Epoch 12/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3405 - accuracy: 0.9244 - val_loss: 0.7507 - val_accuracy: 0.7746\n",
      "Epoch 13/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3059 - accuracy: 0.9346 - val_loss: 0.7513 - val_accuracy: 0.7721\n",
      "Epoch 14/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2718 - accuracy: 0.9484 - val_loss: 0.7281 - val_accuracy: 0.7814\n",
      "Epoch 15/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2410 - accuracy: 0.9557 - val_loss: 0.7289 - val_accuracy: 0.7790\n",
      "Epoch 16/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2147 - accuracy: 0.9654 - val_loss: 0.7157 - val_accuracy: 0.7848\n",
      "Epoch 17/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.1901 - accuracy: 0.9714 - val_loss: 0.7385 - val_accuracy: 0.7770\n",
      "Epoch 18/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.1707 - accuracy: 0.9795 - val_loss: 0.7230 - val_accuracy: 0.7756\n",
      "Epoch 19/20\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.1504 - accuracy: 0.9841 - val_loss: 0.7188 - val_accuracy: 0.7829\n",
      "Epoch 20/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9869 - val_loss: 0.7195 - val_accuracy: 0.7780\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./data/test/\"\n",
    "img_test_files = os.listdir(test_path)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 497ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "japanese_spaniel\n",
      "1/1 [==============================] - 0s 490ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "samoyed\n",
      "1/1 [==============================] - 1s 579ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "english_setter\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "pug\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "tibetan_terrier\n"
     ]
    }
   ],
   "source": [
    "for img in img_test_files:\n",
    "    file_name = os.path.join(test_path, img)\n",
    "    image_test = load_img(file_name, target_size=img_size)\n",
    "    image_test = np.array(image_test)\n",
    "    image_test = image_test.reshape((1, 224, 224, 3))\n",
    "    image_test = extract_feature(\n",
    "        MobileNetV2, mbv2_preprocess, img_size, image_test\n",
    "    )\n",
    "    breed_index = model.predict(image_test).argmax(axis=-1)\n",
    "    breed_label = [\n",
    "        label for label, index in class_to_num.items() if index == breed_index\n",
    "    ][0]\n",
    "\n",
    "    print(breed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
